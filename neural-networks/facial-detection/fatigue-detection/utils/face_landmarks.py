import cv2
import math
import numpy as np
from depthai_nodes.ml.messages import Keypoints

def determine_fatigue(frame: np.ndarray, face_keypoints: Keypoints, pitch_angle: int = 20):
    h, w = frame.shape[:2]
    face_points_2d = np.array([[int(kp.x * w), int(kp.y * h)] for kp in face_keypoints.keypoints])
    
    left_eye_idx = [33, 160, 158, 133, 144, 153]
    right_eye_idx = [263, 387, 385, 362, 373, 380]
    
    left_eye = face_points_2d[left_eye_idx]
    right_eye = face_points_2d[right_eye_idx]
    
    pose_indices = [199, 4, 33, 263, 61, 291]
    image_points = face_points_2d[pose_indices].astype("double")
    
    success, rotation_vector, translation_vector, camera_matrix, dist_coeffs = get_pose_estimation(frame.shape, image_points)
    
    head_tilted = False
    if success:
        pitch, yaw, roll = get_euler_angles(rotation_vector)
        if pitch < - pitch_angle:
            head_tilted = True
    
    left_ear = calc_eye_aspect_ratio(left_eye)
    right_ear = calc_eye_aspect_ratio(right_eye)
    ear = (left_ear + right_ear) / 2.0
    eyes_closed = True if ear < 0.15 else False
            
    return head_tilted, eyes_closed

def calc_eye_aspect_ratio(eye_points):
    A = np.linalg.norm(eye_points[1] - eye_points[4])
    B = np.linalg.norm(eye_points[2] - eye_points[5])
    C = np.linalg.norm(eye_points[0] - eye_points[3])
    return (A + B) / (2.0 * C)


def get_pose_estimation(img_shape, image_points):

    # 3D model points corresponding to the landmarks above.
    model_points = np.array([
        (0.0, -7.9422, 5.1812),    # Chin
        (0.0, -0.4632, 7.5866),     # Nose tip
        (-4.4459, 2.6640, 3.1734),   # Left eye corner
        (4.4459, 2.6640, 3.1734),    # Right eye corner
        (-2.4562, -4.3426, 4.2839),  # Left mouth corner
        (2.4562, -4.3426, 4.2839)    # Right mouth corner
    ], dtype="double")
    
    focal_length = img_shape[1]
    center = (img_shape[1] / 2, img_shape[0] / 2)
    camera_matrix = np.array([
        [focal_length, 0, center[0]],
        [0, focal_length, center[1]],
        [0, 0, 1]
    ], dtype="double")
    
    # Assuming no lens distortion
    dist_coeffs = np.zeros((4, 1))
    
    # Solve for pose
    success, rotation_vector, translation_vector = cv2.solvePnP(
        model_points, image_points, 
        camera_matrix, dist_coeffs,
        flags=cv2.SOLVEPNP_ITERATIVE
    )
    return success, rotation_vector, translation_vector, camera_matrix, dist_coeffs


def get_euler_angles(rotation_vector):
    # Convert rotation vector to rotation matrix
    rotation_matrix, _ = cv2.Rodrigues(rotation_vector)
    
    # Compute Euler angles from the rotation matrix.
    sy = math.sqrt(rotation_matrix[0, 0]**2 + rotation_matrix[1, 0]**2)
    
    singular = sy < 1e-6
    if not singular:
        pitch = math.atan2(rotation_matrix[2, 1], rotation_matrix[2, 2])
        yaw = math.atan2(-rotation_matrix[2, 0], sy)
        roll = math.atan2(rotation_matrix[1, 0], rotation_matrix[0, 0])
    else:
        # Fallback for singular case
        pitch = math.atan2(-rotation_matrix[1, 2], rotation_matrix[1, 1])
        yaw = math.atan2(-rotation_matrix[2, 0], sy)
        roll = 0
    
    # Convert radians to degrees
    pitch_deg = pitch * 180 / math.pi
    yaw_deg = yaw * 180 / math.pi
    roll_deg = roll * 180 / math.pi
    
    return pitch_deg, yaw_deg, roll_deg